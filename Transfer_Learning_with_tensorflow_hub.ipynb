{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer Learning with tensorflow hub",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnymephisto/Machine-Learning-and-Deep-Learning-Experiments/blob/master/Transfer_Learning_with_tensorflow_hub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WM7hp2LnrMKH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41278c38-5b91-4458-882d-04254a19e20b"
      },
      "cell_type": "code",
      "source": [
        "#pip install -q tensorflow-hub\n",
        "\n",
        "import os\n",
        "from urllib import request\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.python import debug as tf_debug\n",
        "\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.12.0', True, True, '/device:GPU:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "Z2G71275rVnx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#will take from tmp if already downloaded dataset\n",
        "data_dir = '/tmp/datasets/dogscats'\n",
        "\n",
        "\n",
        "if not os.path.isdir(data_dir):\n",
        "    # Download the data zip to our data directory and extract\n",
        "    fallback_url = 'http://files.fast.ai/data/dogscats.zip'\n",
        "    tf.keras.utils.get_file(\n",
        "        os.path.join('/tmp', os.path.basename(fallback_url)), \n",
        "        fallback_url, \n",
        "        cache_dir='/tmp',\n",
        "        extract=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lcY_SH0Xriax",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def _img_string_to_tensor(image_string, image_size=(299, 299)):\n",
        "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
        "    # Convert from full range of uint8 to range [0,1] of float32.\n",
        "    image_decoded_as_float = tf.image.convert_image_dtype(image_decoded, dtype=tf.float32)\n",
        "    # Resize to expected\n",
        "    image_resized = tf.image.resize_images(image_decoded_as_float, size=image_size)\n",
        "    \n",
        "    return image_resized\n",
        "\n",
        "def make_dataset(file_pattern, image_size=(299, 299), shuffle=False, batch_size=64, num_epochs=None, buffer_size=4096):\n",
        "    \n",
        "    def _path_to_img(path):\n",
        "        # Get the parent folder of this file to get it's class name\n",
        "        label = tf.string_split([path], delimiter='/').values[-2]\n",
        "        \n",
        "        # Read in the image from disk\n",
        "        image_string = tf.read_file(path)\n",
        "        image_resized = _img_string_to_tensor(image_string, image_size)\n",
        "        \n",
        "        return { 'image': image_resized }, label\n",
        "    \n",
        "    dataset = tf.data.Dataset.list_files(file_pattern)\n",
        "\n",
        "    if shuffle:\n",
        "        dataset = dataset.apply(tf.data.experimental.shuffle_and_repeat(buffer_size, num_epochs))\n",
        "    else:\n",
        "        dataset = dataset.repeat(num_epochs)\n",
        "\n",
        "    dataset = dataset.map(_path_to_img, num_parallel_calls=os.cpu_count())\n",
        "    dataset = dataset.batch(batch_size).prefetch(buffer_size)\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5z5XevPPr1UQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_fn(features, labels, mode, params):\n",
        "    is_training = mode == tf.estimator.ModeKeys.TRAIN\n",
        "    module_training = is_training and params.get('train_module', False)\n",
        "\n",
        "    module = hub.Module(params['module_spec'], trainable=module_training, name=params['module_name'])\n",
        "    bottleneck_tensor = module(features['image'])\n",
        "\n",
        "    NUM_CLASSES = len(params['label_vocab'])\n",
        "    logit_units = 1 if NUM_CLASSES == 2 else NUM_CLASSES\n",
        "    logits = tf.keras.layers.Dense(logit_units)(bottleneck_tensor)\n",
        "\n",
        "    if NUM_CLASSES == 2:\n",
        "        head = tf.contrib.estimator.binary_classification_head(label_vocabulary=params['label_vocab'])\n",
        "    else:\n",
        "        head = tf.contrib.estimator.multi_class_head(n_classes=NUM_CLASSES, label_vocabulary=params['label_vocab'])\n",
        "\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])\n",
        "    return head.create_estimator_spec(\n",
        "        features, mode, logits, labels, optimizer=optimizer\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0B_D5x_rr6Iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "2240871b-34b4-4704-b7ca-e65a141e7a5b"
      },
      "cell_type": "code",
      "source": [
        "def train(model_directory, data_directory):\n",
        "\n",
        "  \n",
        "    params = {\n",
        "        'module_spec': 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1',\n",
        "        'module_name': 'inception_v3',\n",
        "        'learning_rate': 1e-3,\n",
        "        'train_module': True,  # Retrain the last layer\n",
        "        'label_vocab': os.listdir(os.path.join(data_dir, 'valid'))\n",
        "    }\n",
        "\n",
        "    run_config = tf.estimator.RunConfig()\n",
        "\n",
        "    classifier = tf.estimator.Estimator(\n",
        "        model_fn=model_fn,\n",
        "        model_dir=model_directory,\n",
        "        config=run_config,\n",
        "        params=params\n",
        "    )\n",
        "\n",
        "    input_img_size = hub.get_expected_image_size(hub.Module(params['module_spec']))\n",
        "\n",
        "    train_files = os.path.join(data_directory, 'train', '**/*.jpg')\n",
        "    train_input_fn = lambda: make_dataset(train_files, image_size=input_img_size, batch_size=8, shuffle=True)\n",
        "    train_spec = tf.estimator.TrainSpec(train_input_fn, max_steps=20)\n",
        "\n",
        "    eval_files = os.path.join(data_directory, 'valid', '**/*.jpg')\n",
        "    eval_input_fn = lambda: make_dataset(eval_files, image_size=input_img_size, batch_size=1)\n",
        "    eval_spec = tf.estimator.EvalSpec(eval_input_fn)\n",
        "\n",
        "    tf.estimator.train_and_evaluate(classifier, train_spec, eval_spec)\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "train('/tmp/dogscats/run1', data_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/dogscats/run3', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdce0843780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From <ipython-input-3-7b28ca0c3017>:25: shuffle_and_repeat (from tensorflow.contrib.data.python.ops.shuffle_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.shuffle_and_repeat(...)`.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/dogscats/run3/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.7866682, step = 0\n",
            "INFO:tensorflow:Saving checkpoints for 20 into /tmp/dogscats/run3/model.ckpt.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2019-01-25-06:41:31\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/dogscats/run3/model.ckpt-20\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Evaluation [10/100]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8wHybahbxEYk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}